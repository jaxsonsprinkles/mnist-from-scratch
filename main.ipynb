{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac85e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4f4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# to remove outdated numpy matmult errors\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, message=\"__array_wrap__ must accept context and return_scalar arguments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6484a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    transforms=[\n",
    "    torchvision.transforms.ToTensor(),\n",
    "]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfb5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8725a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  15000\n",
      "Test images:  2500\n"
     ]
    }
   ],
   "source": [
    "print(\"Training images: \", len(trainloader))\n",
    "print(\"Test images: \", len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b7dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "trainiter = iter(trainloader)\n",
    "images, labels = next(trainiter)\n",
    "\n",
    "first_batch = images[:4]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(15,3))\n",
    "for i in range(4):\n",
    "    reshaped = np.transpose(first_batch[i], (1,2,0))\n",
    "    plt.imshow(reshaped)\n",
    "    \n",
    "    \n",
    "    axes[i].imshow(reshaped)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae325ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "Min pixel:  tensor(0.)\n",
      "Max pixel:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(images[0].size())\n",
    "print(\"Min pixel: \", torch.min(images))\n",
    "print(\"Max pixel: \", torch.max(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4522d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    images = images.view(images.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637ebb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes):\n",
    "        one_hot = np.zeros((labels.shape[0], num_classes))\n",
    "        one_hot[np.arange(labels.shape[0]), labels] = 1.0\n",
    "def softmax(x):\n",
    "    return np.exp(x) / sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d692e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.w1 = np.random.randn(784,128)*0.01\n",
    "        self.b1 = np.zeros(128)\n",
    "        self.w2 = np.random.randn(128,10)*0.01\n",
    "        self.b2 = np.zeros(10)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "        self.z1 = image @ self.w1 + self.b1\n",
    "        self.a1 = np.maximum(0, self.z1) # relu\n",
    "        self.z2 = self.a1 @  self.w2 + self.b2\n",
    "        self.softmaxed = softmax(self.z2)\n",
    "\n",
    "    \n",
    "    def backward(self, image, labels):\n",
    "        one_hot_encoded = one_hot(labels, 10)\n",
    "        \n",
    "        # A lot of this is copied because I haven't taken multivariable yet\n",
    "        dz = self.softmaxed - self.one_hot_encoded\n",
    "        self.dW2 = self.a1.T.dot(dz)        \n",
    "        self.db2 = np.sum(dz, axis=0)\n",
    "        dh = dz.dot(self.w2.T)\n",
    "        da1 = dh * (self.a1 > 0)\n",
    "        self.dW1 = image.numpy().T.dot(da1) \n",
    "        self.db1 = np.sum(da1, axis=0) \n",
    "\n",
    "        \n",
    "    \n",
    "    def update_params(self, lr):\n",
    "        self.W1 = self.W1-self.dW1*lr\n",
    "        self.W2 = self.W2-self.dW2*lr\n",
    "        self.b1 = self.b1-self.db1*lr\n",
    "        self.b2 = self.b2-self.db2*lr\n",
    "    \n",
    "    def train(self, image, labels, iterations, learning_rate):\n",
    "        print(\"Training initiated\")\n",
    "\n",
    "        for i in range(iterations):\n",
    "            self.forward(image)\n",
    "            self.backward(image, labels)\n",
    "            self.update_params(learning_rate)\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Iteration {i} completed\")\n",
    "        \n",
    "        print(\"Training completed\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9d65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initiated\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = Model()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, image, labels, iterations, learning_rate)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.forward(image)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mself\u001b[39m.update_params(learning_rate)\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mModel.backward\u001b[39m\u001b[34m(self, image, labels)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, labels):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     one_hot_encoded = \u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmaxed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# A lot of this is copied because I haven't taken multivariable yet\u001b[39;00m\n\u001b[32m     21\u001b[39m     dz = \u001b[38;5;28mself\u001b[39m.softmaxed - \u001b[38;5;28mself\u001b[39m.one_hot_encoded\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mone_hot\u001b[39m\u001b[34m(labels, num_classes)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_hot\u001b[39m(labels, num_classes):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m         one_hot = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m         one_hot[np.arange(labels.shape[\u001b[32m0\u001b[39m]), labels] = \u001b[32m1.0\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train(images, labels, 10, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3fc652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
