{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac85e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6484a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    transforms=[\n",
    "    torchvision.transforms.ToTensor(),\n",
    "]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cfb5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8725a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  15000\n",
      "Test images:  2500\n"
     ]
    }
   ],
   "source": [
    "print(\"Training images: \", len(trainloader))\n",
    "print(\"Test images: \", len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b7dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "trainiter = iter(trainloader)\n",
    "images, labels = next(trainiter)\n",
    "\n",
    "first_batch = images[:4]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(15,3))\n",
    "for i in range(4):\n",
    "    reshaped = np.transpose(first_batch[i], (1,2,0))\n",
    "    plt.imshow(reshaped)\n",
    "    \n",
    "    \n",
    "    axes[i].imshow(reshaped)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae325ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "Min pixel:  tensor(0.)\n",
      "Max pixel:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(images[0].size())\n",
    "print(\"Min pixel: \", torch.min(images))\n",
    "print(\"Max pixel: \", torch.max(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4522d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    images = images.view(images.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d692e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.w1 = torch.randn(784,128)*0.01\n",
    "        self.b1 = torch.zeros(128)\n",
    "        self.w2 = torch.randn(128,10)*0.01\n",
    "        self.b2 = torch.zeros(10)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        self.z1 = torch.matmul(image, self.w1) + self.b1\n",
    "        self.a1 = torch.sigmoid(self.z1)\n",
    "        self.z2 = torch.matmul(self.a1, self.w2) + self.b2\n",
    "        return torch.sigmoid(self.z2)\n",
    "\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        softmaxed = torch.softmax(output, dim=1)\n",
    "        crossentropy = -torch.log(softmaxed[label])\n",
    "\n",
    "        print(\"Label: \", label)\n",
    "        print(\"Predicted prob:\", softmaxed[label])\n",
    "        print(\"Loss: \", crossentropy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef9d65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5057, 0.4934, 0.4828, 0.4989, 0.5137, 0.5061, 0.5204, 0.4843, 0.5023,\n",
      "        0.4655])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m output = model.forward(images[\u001b[32m0\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mModel.loss\u001b[39m\u001b[34m(self, output, label)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, output, label):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     softmaxed = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     crossentropy = -torch.log(softmaxed[label])\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLabel: \u001b[39m\u001b[33m\"\u001b[39m, label)\n",
      "\u001b[31mIndexError\u001b[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "output = model.forward(images[0])\n",
    "print(output)\n",
    "model.loss(output, labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
